{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "[W12-D2] Spark 실습.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qcKAZnNuSUpg"
      },
      "source": [
        "PySpark을 로컬 머신에 설치하고 노트북을 사용하기 보다는 머신 러닝 관련 다양한 라이브러리가 이미 설치되었고 좋은 하드웨어를 제공해주는 Google Colab을 통해 실습을 진행한다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c5gYAes9SdM5"
      },
      "source": [
        "이를 위해 pyspark과 Py4J 패키지를 설치한다. Py4J 패키지는 파이썬 프로그램이 자바 가상머신상의 오브젝트들을 접근할 수 있게 해준다. LocalStandalone Spark을 사용한다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SE0VhL0g1no8"
      },
      "source": [
        "### 먼저 PySpark과 Py4J를 설치하자"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YXgIyS_F0Kar",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "49046c02-f46a-44eb-9175-fc5099ff90a8"
      },
      "source": [
        "!pip install pyspark==3.0.1 py4j==0.10.9 "
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pyspark==3.0.1 in /usr/local/lib/python3.7/dist-packages (3.0.1)\n",
            "Requirement already satisfied: py4j==0.10.9 in /usr/local/lib/python3.7/dist-packages (0.10.9)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AdHzVBH4TpII",
        "outputId": "c2997e41-6193-419b-9068-ec44249184a7"
      },
      "source": [
        "!ls -tl sample_data"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "total 55504\n",
            "-rw-r--r-- 1 root root 18289443 Jul 16 13:20 mnist_test.csv\n",
            "-rw-r--r-- 1 root root 36523880 Jul 16 13:20 mnist_train_small.csv\n",
            "-rw-r--r-- 1 root root   301141 Jul 16 13:20 california_housing_test.csv\n",
            "-rw-r--r-- 1 root root  1706430 Jul 16 13:20 california_housing_train.csv\n",
            "-rwxr-xr-x 1 root root     1697 Jan  1  2000 anscombe.json\n",
            "-rwxr-xr-x 1 root root      930 Jan  1  2000 README.md\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FNwc3F_Az6e6"
      },
      "source": [
        "### Spark Session 만들기\n",
        "**Spark Session** : Spark Session은 Spark 2.0부터 엔트리포이트로 사용한다. 그 이전에는 SparkContext가 사용되었다. Spark Sessiond을 이용해 RDD, 데이터 프레임 등을 만든다. Spark Session은 Spark Session.builder를 호출하여 생성하며 다양한 함수들을 통해 세부 설정이 가능하다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "RveyavjYz6e7"
      },
      "source": [
        "from pyspark.sql import SparkSession\n",
        "\n",
        "spark = SparkSession \\\n",
        "    .builder \\\n",
        "    .master(\"local[*]\") \\\n",
        "    .appName(\"PySpark Tutorial\") \\\n",
        "    .getOrCreate()\n",
        "\n",
        "# spark = SparkSession \\\n",
        "#     .builder \\\n",
        "#     .master(\"local[*]\") \\           ## 사용하고싶은 SparkCluster이름[사용하고 싶은 cpu의 개수]\n",
        "#     .appName(\"PySpark Tutorial\") \\\n",
        "#     .getOrCreate()"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 216
        },
        "id": "ESRqAxzWVYps",
        "outputId": "df408dd4-0aed-4997-fc3e-85e5641180a6"
      },
      "source": [
        "spark"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "            <div>\n",
              "                <p><b>SparkSession - in-memory</b></p>\n",
              "                \n",
              "        <div>\n",
              "            <p><b>SparkContext</b></p>\n",
              "\n",
              "            <p><a href=\"http://d8ed71cc1dd4:4040\">Spark UI</a></p>\n",
              "\n",
              "            <dl>\n",
              "              <dt>Version</dt>\n",
              "                <dd><code>v3.0.1</code></dd>\n",
              "              <dt>Master</dt>\n",
              "                <dd><code>local[*]</code></dd>\n",
              "              <dt>AppName</dt>\n",
              "                <dd><code>PySpark Tutorial</code></dd>\n",
              "            </dl>\n",
              "        </div>\n",
              "        \n",
              "            </div>\n",
              "        "
            ],
            "text/plain": [
              "<pyspark.sql.session.SparkSession at 0x7fe2c3444bd0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QnQgj127V5SW"
      },
      "source": [
        "### Python 객체를 RDD로 변환해보기"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v_MrHKr4V-A5"
      },
      "source": [
        "#### 1. Python 리스트 생성"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HsXN0fILV4zB"
      },
      "source": [
        "name_list_json = ['{\"name\" : \"keeyong\"}', '{\"name\" : \"benjamin\"}', '{\"name\" : \"claire\"}']"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jrCXwXx5WRbs",
        "outputId": "52865384-b389-4efb-d580-9cdd849162da"
      },
      "source": [
        "for n in name_list_json :\n",
        "    print(n)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{\"name\" : \"keeyong\"}\n",
            "{\"name\" : \"benjamin\"}\n",
            "{\"name\" : \"claire\"}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5wisDzg-WWEP",
        "outputId": "da86a425-97a6-4fdc-ab03-c5ca19bf72c8"
      },
      "source": [
        "import json\n",
        "\n",
        "for n in name_list_json :\n",
        "    jn = json.loads(n)\n",
        "    print(jn[\"name\"])"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "keeyong\n",
            "benjamin\n",
            "claire\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i3DevREsWss7"
      },
      "source": [
        "#### 2. 파이썬 리스트를 RDD로 변환.  \n",
        "- RDD로 변환되는 순간 Spark 클러스터의 서버들에 데이터가 나눠 저장됨(파티션).  \n",
        "- 또한 Lazy Execution이 된다는 점 기억 (액션을 취하기 전까지는 spark가 실행이 안됨)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YZ7vFUOTWWcR"
      },
      "source": [
        "rdd = spark.sparkContext.parallelize(name_list_json)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1gkm88ReWWf4",
        "outputId": "071ad8f0-9791-470f-c640-ac4fec4f4c07"
      },
      "source": [
        "rdd"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ParallelCollectionRDD[0] at readRDDFromFile at PythonRDD.scala:262"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DNG70-T2WWjl",
        "outputId": "c9323e02-1d1c-475a-9d72-051a4505856c"
      },
      "source": [
        "rdd.count()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gz2Kuj9CWWm9"
      },
      "source": [
        "# map : rdd의 레코드들을 다음 액션을 통해 새로운 rdd 객체 생성\n",
        "# string이었던 rdd의 원소들이 python의 dictionary형으로 바뀜\n",
        "parsed_rdd = rdd.map(lambda el:json.loads(el))  "
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WiSDIQnwYCRF",
        "outputId": "6b16377f-d661-4d2a-d701-da307d1bbc23"
      },
      "source": [
        "parsed_rdd"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "PythonRDD[2] at RDD at PythonRDD.scala:53"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Al5lG8pkWWqr",
        "outputId": "d5735ec4-c47a-426f-87a0-3a7c10d6a741"
      },
      "source": [
        "parsed_rdd.collect()  # rdd가 Python 프로그래밍으로 넘어옴"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'name': 'keeyong'}, {'name': 'benjamin'}, {'name': 'claire'}]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VoUDWV0GWWuY"
      },
      "source": [
        "parsed_name_rdd = rdd.map(lambda el:json.loads(el)[\"name\"])"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "83UvTpe1WWyO",
        "outputId": "11af3072-c78e-4e33-9cd9-3aef17b96346"
      },
      "source": [
        "parsed_name_rdd.collect()   # 받아오는 데이터가 너무 커지면 안됨. 못 받아옴 따로 어딘가에 저장해야함"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['keeyong', 'benjamin', 'claire']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gNstybOlYQ5A"
      },
      "source": [
        "### 파이썬 리스트를 데이터프레임으로 변환하기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5IbnVS0XWW16"
      },
      "source": [
        "from pyspark.sql.types import StringType\n",
        "\n",
        "df = spark.createDataFrame(name_list_json, StringType())"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZK8FoND3YP3o",
        "outputId": "8f74e925-d26b-493a-eb27-9f12ade83905"
      },
      "source": [
        "df.count()"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c4Pdvv6YYQCB",
        "outputId": "ec8f6087-6908-4680-e811-28ef6b33f962"
      },
      "source": [
        "df.printSchema()   # 기본적으로 필드 이름이 value가 됨"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "root\n",
            " |-- value: string (nullable = true)\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JLCiT2RLYQF-",
        "outputId": "3da22f2b-778b-473f-b0b1-c19006e4adf5"
      },
      "source": [
        "df.select('*').collect()  # '*'는 모든 레코드"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Row(value='{\"name\" : \"keeyong\"}'),\n",
              " Row(value='{\"name\" : \"benjamin\"}'),\n",
              " Row(value='{\"name\" : \"claire\"}')]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g9CI6eb_YQJE",
        "outputId": "306f2d53-0716-4caf-bce1-c74ad81398e4"
      },
      "source": [
        "df.select('value').collect()"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Row(value='{\"name\" : \"keeyong\"}'),\n",
              " Row(value='{\"name\" : \"benjamin\"}'),\n",
              " Row(value='{\"name\" : \"claire\"}')]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WuIWqGibWW5g"
      },
      "source": [
        "from pyspark.sql import Row\n",
        "\n",
        "row = Row(\"name\")  # Or some other column name\n",
        "df_name = parsed_name_rdd.map(row).toDF()  # row라는 필드를 주면서 DF로 바꿈"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gGUYGAlbZMTI",
        "outputId": "1e7063df-bd36-4440-a24a-e0c11647afee"
      },
      "source": [
        "df_name.printSchema()  # 필드 이름이 name으로 바뀜"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "root\n",
            " |-- name: string (nullable = true)\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OakIHAGgZAR1",
        "outputId": "7d839827-5171-4f72-9431-a5e4294e3326"
      },
      "source": [
        "df_name.select('name').collect()"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Row(name='keeyong'), Row(name='benjamin'), Row(name='claire')]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    }
  ]
}